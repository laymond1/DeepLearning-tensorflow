{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep CNN : 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droupout training : 0.5 ~ 0.7 But Test : Must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1]) # image 28 X 28 X 1(Black/White)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conv layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation (오래 걸린다...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.437903225\n",
      "Epoch: 0002 cost = 0.093770534\n",
      "Epoch: 0003 cost = 0.069391579\n",
      "Epoch: 0004 cost = 0.057282076\n",
      "Epoch: 0005 cost = 0.049474598\n",
      "Epoch: 0006 cost = 0.044198364\n",
      "Epoch: 0007 cost = 0.041221151\n",
      "Epoch: 0008 cost = 0.035988780\n",
      "Epoch: 0009 cost = 0.035161204\n",
      "Epoch: 0010 cost = 0.032376616\n",
      "Epoch: 0011 cost = 0.030243842\n",
      "Epoch: 0012 cost = 0.028835049\n",
      "Epoch: 0013 cost = 0.028259837\n",
      "Epoch: 0014 cost = 0.026552599\n",
      "Epoch: 0015 cost = 0.025959235\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9934\n",
      "Label:  [0]\n",
      "Prediction:  [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109a97908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
