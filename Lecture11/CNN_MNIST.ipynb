{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST data with CNN : 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1]) # image 28 X 28 X 1(Black/White)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# L1 Imgin shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01)) # 3 X 3 X 1 filter 32개\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(L1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "print(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "print(L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# L2 Imain shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "print(L2)\n",
    "L2 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "print(L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final FC 7 X 7 X 64 inputs -> 10 outputs\n",
    "W3 = tf.get_variable(\"W3\", shape=[7*7*64, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# Cost & Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation (오래 걸린다...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.393701393\n",
      "Epoch: 0002 cost = 0.114355319\n",
      "Epoch: 0003 cost = 0.080066625\n",
      "Epoch: 0004 cost = 0.066732820\n",
      "Epoch: 0005 cost = 0.056383681\n",
      "Epoch: 0006 cost = 0.049947360\n",
      "Epoch: 0007 cost = 0.043977146\n",
      "Epoch: 0008 cost = 0.039606544\n",
      "Epoch: 0009 cost = 0.034747794\n",
      "Epoch: 0010 cost = 0.030899272\n",
      "Epoch: 0011 cost = 0.028846722\n",
      "Epoch: 0012 cost = 0.024618106\n",
      "Epoch: 0013 cost = 0.023081781\n",
      "Epoch: 0014 cost = 0.019020988\n",
      "Epoch: 0015 cost = 0.017778803\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9851\n",
      "Label:  [2]\n",
      "Prediction:  [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e512a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
