{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.921978 [[-0.34420124 -1.8207142  -0.12573427]\n",
      " [ 0.08537128  0.05464277 -1.8231264 ]\n",
      " [-1.1955417   0.4323903  -0.46635452]]\n",
      "1 4.812258 [[-0.32103077 -1.8808647  -0.08875427]\n",
      " [ 0.2438317  -0.2027385  -1.7242056 ]\n",
      " [-1.0352896   0.18526918 -0.37948552]]\n",
      "2 2.7991672 [[-0.30384377 -1.9339858  -0.05282017]\n",
      " [ 0.38428107 -0.43978906 -1.6276044 ]\n",
      " [-0.8876472  -0.04710893 -0.2947498 ]]\n",
      "3 1.5486813 [[-0.32499534 -1.9456648  -0.01998967]\n",
      " [ 0.3251382  -0.47007355 -1.538177  ]\n",
      " [-0.9165871  -0.09125988 -0.22165895]]\n",
      "4 1.3264376 [[-0.34320235 -1.9560881   0.00864068]\n",
      " [ 0.2781689  -0.50235456 -1.4589267 ]\n",
      " [-0.9344598  -0.13109851 -0.16394766]]\n",
      "5 1.173268 [[-0.35987076 -1.9623232   0.03154425]\n",
      " [ 0.23476529 -0.5231969  -1.3946807 ]\n",
      " [-0.94931316 -0.15238027 -0.12781249]]\n",
      "6 1.0875554 [[-0.37283868 -1.9667535   0.04894246]\n",
      " [ 0.2071617  -0.54359156 -1.3466824 ]\n",
      " [-0.9496015  -0.16755359 -0.11235084]]\n",
      "7 1.0464437 [[-0.38442868 -1.9681535   0.06193249]\n",
      " [ 0.18360297 -0.5534992  -1.3132161 ]\n",
      " [-0.9463902  -0.16924231 -0.11387338]]\n",
      "8 1.025426 [[-0.39388824 -1.9691349   0.07237349]\n",
      " [ 0.16979255 -0.56398535 -1.2889196 ]\n",
      " [-0.93441343 -0.17008863 -0.12500386]]\n",
      "9 1.0106727 [[-0.4031359  -1.9689507   0.08143701]\n",
      " [ 0.15575048 -0.5691322  -1.2697307 ]\n",
      " [-0.9229543  -0.1654011  -0.14115053]]\n",
      "10 0.9975498 [[-0.41155803 -1.9690775   0.08998588]\n",
      " [ 0.14550811 -0.57609296 -1.2525276 ]\n",
      " [-0.90829027 -0.16262276 -0.15859292]]\n",
      "11 0.98508435 [[-0.42009467 -1.9687666   0.09821168]\n",
      " [ 0.13386935 -0.5804432  -1.2365386 ]\n",
      " [-0.89523554 -0.15764646 -0.17662397]]\n",
      "12 0.9731144 [[-0.42820513 -1.9687661   0.10632168]\n",
      " [ 0.1240441  -0.5861359  -1.2210207 ]\n",
      " [-0.88081807 -0.15438496 -0.19430296]]\n",
      "13 0.9616054 [[-0.43638587 -1.9685473   0.11428367]\n",
      " [ 0.1132106  -0.5902597  -1.2060635 ]\n",
      " [-0.8676518  -0.15002069 -0.21183349]]\n",
      "14 0.95053947 [[-0.44427717 -1.9685428   0.12217048]\n",
      " [ 0.10347497 -0.5951659  -1.1914216 ]\n",
      " [-0.8537828  -0.14684711 -0.22887613]]\n",
      "15 0.9399003 [[-0.4521761  -1.9684157   0.12994234]\n",
      " [ 0.09314205 -0.5990299  -1.1772248 ]\n",
      " [-0.8407824  -0.1430774  -0.24564624]]\n",
      "16 0.92967194 [[-0.4598565  -1.9684318   0.13763884]\n",
      " [ 0.0835405  -0.6033088  -1.1633443 ]\n",
      " [-0.8274154  -0.14012656 -0.26196408]]\n",
      "17 0.91983867 [[-0.46750483 -1.968378    0.1452333 ]\n",
      " [ 0.07361124 -0.6068568  -1.1498669 ]\n",
      " [-0.8146642  -0.13686442 -0.2779774 ]]\n",
      "18 0.91038495 [[-0.474979   -1.9684213   0.15275086]\n",
      " [ 0.06419678 -0.6105968  -1.1367124 ]\n",
      " [-0.80174357 -0.13418345 -0.29357898]]\n",
      "19 0.9012958 [[-0.48239887 -1.9684256   0.16017503]\n",
      " [ 0.0546222  -0.61380106 -1.1239336 ]\n",
      " [-0.78927964 -0.13135989 -0.30886647]]\n",
      "20 0.8925558 [[-0.48967442 -1.9684976   0.16752256]\n",
      " [ 0.04542843 -0.617064   -1.1114768 ]\n",
      " [-0.7767668  -0.12896465 -0.32377458]]\n",
      "21 0.8841506 [[-0.49688423 -1.9685488   0.17478353]\n",
      " [ 0.03617889 -0.6199181  -1.0993731 ]\n",
      " [-0.76460975 -0.12652734 -0.3383689 ]]\n",
      "22 0.8760659 [[-0.50397086 -1.9686481   0.18196948]\n",
      " [ 0.02722553 -0.6227524  -1.0875854 ]\n",
      " [-0.7524783  -0.12441751 -0.35261017]]\n",
      "23 0.868288 [[-0.51098686 -1.9687372   0.18907464]\n",
      " [ 0.01828178 -0.6252632  -1.0761309 ]\n",
      " [-0.7406377  -0.1223247  -0.3665436 ]]\n",
      "24 0.86080325 [[-0.5178954  -1.9688613   0.19610722]\n",
      " [ 0.00957976 -0.62770927 -1.0649828 ]\n",
      " [-0.72886896 -0.12049068 -0.38014632]]\n",
      "25 0.85359895 [[-5.2473235e-01 -1.9689813e+00  2.0306408e-01]\n",
      " [ 9.2871767e-04 -6.2989140e-01 -1.0541496e+00]\n",
      " [-7.1734816e-01 -1.1870731e-01 -3.9345050e-01]]\n",
      "26 0.84666276 [[-0.53147393 -1.9691268   0.20995128]\n",
      " [-0.00751643 -0.6319847  -1.0436112 ]\n",
      " [-0.7059281  -0.11713425 -0.4064436 ]]\n",
      "27 0.8399825 [[-0.53814524 -1.9692715   0.21676731]\n",
      " [-0.01588433 -0.63385755 -1.0333704 ]\n",
      " [-0.6947269  -0.11562971 -0.41914934]]\n",
      "28 0.83354676 [[-0.5447311  -1.9694352   0.22351679]\n",
      " [-0.02407045 -0.6356303  -1.0234115 ]\n",
      " [-0.68364424 -0.11429989 -0.43156183]]\n",
      "29 0.82734483 [[-0.55124927 -1.9695995   0.23019928]\n",
      " [-0.03216273 -0.63721555 -1.013734  ]\n",
      " [-0.6727602  -0.11304668 -0.4436991 ]]\n",
      "30 0.821366 [[-0.5576902  -1.9697777   0.23681842]\n",
      " [-0.04008986 -0.6386975  -1.0043249 ]\n",
      " [-0.6620054  -0.11194111 -0.4555594 ]]\n",
      "31 0.81560016 [[-0.5640669  -1.969957    0.2433744 ]\n",
      " [-0.04791272 -0.6400178  -0.99518174]\n",
      " [-0.65143466 -0.11091412 -0.46715716]]\n",
      "32 0.810038 [[-0.57037336 -1.9701463   0.24987024]\n",
      " [-0.05558226 -0.64123654 -0.98629344]\n",
      " [-0.6409994  -0.11001345 -0.47849312]]\n",
      "33 0.8046704 [[-0.5766193  -1.9703366   0.2563065 ]\n",
      " [-0.06314119 -0.6423149  -0.9776561 ]\n",
      " [-0.6307372  -0.10918971 -0.48957905]]\n",
      "34 0.7994882 [[-0.5828013  -1.9705338   0.2626857 ]\n",
      " [-0.07055558 -0.6432963  -0.96926033]\n",
      " [-0.62061363 -0.10847484 -0.5004175 ]]\n",
      "35 0.79448366 [[-0.58892655 -1.9707315   0.26900864]\n",
      " [-0.07785574 -0.6441551  -0.96110135]\n",
      " [-0.6106548  -0.10783301 -0.5110182 ]]\n",
      "36 0.7896487 [[-0.59499323 -1.9709337   0.27527747]\n",
      " [-0.08501799 -0.6449233  -0.95317084]\n",
      " [-0.6008356  -0.1072856  -0.5213848 ]]\n",
      "37 0.7849758 [[-0.6010071  -1.9711355   0.28149316]\n",
      " [-0.09206424 -0.64558417 -0.9454637 ]\n",
      " [-0.59117424 -0.10680603 -0.5315257 ]]\n",
      "38 0.78045785 [[-0.6069672  -1.9713398   0.28765756]\n",
      " [-0.09897795 -0.64616174 -0.9379725 ]\n",
      " [-0.58165246 -0.1064085  -0.541445  ]]\n",
      "39 0.7760882 [[-0.6128782  -1.971543    0.29377168]\n",
      " [-0.1057751  -0.6466452  -0.9306919 ]\n",
      " [-0.5722827  -0.10607307 -0.55115026]]\n",
      "40 0.7718601 [[-0.61873984 -1.9717468   0.29983717]\n",
      " [-0.11244415 -0.64705294 -0.9236151 ]\n",
      " [-0.5630513  -0.10580896 -0.5606457 ]]\n",
      "41 0.7677678 [[-0.6245559  -1.9719486   0.3058551 ]\n",
      " [-0.11899706 -0.64737827 -0.9167369 ]\n",
      " [-0.5539669  -0.10560093 -0.5699381 ]]\n",
      "42 0.76380503 [[-0.63032657 -1.9721497   0.3118269 ]\n",
      " [-0.12542568 -0.6476356  -0.910051  ]\n",
      " [-0.5450191  -0.10545494 -0.5790319 ]]\n",
      "43 0.7599665 [[-0.636055   -1.972348    0.31775364]\n",
      " [-0.13173915 -0.6478208  -0.9035523 ]\n",
      " [-0.53621376 -0.10535902 -0.5879331 ]]\n",
      "44 0.756247 [[-0.64174163 -1.9725442   0.32363656]\n",
      " [-0.13793175 -0.6479454  -0.8972351 ]\n",
      " [-0.5275427  -0.10531688 -0.5966463 ]]\n",
      "45 0.7526413 [[-0.6473892  -1.9727368   0.3294767 ]\n",
      " [-0.14401065 -0.6480072  -0.8910944 ]\n",
      " [-0.5190099  -0.10531904 -0.605177  ]]\n",
      "46 0.7491448 [[-0.6529982  -1.9729264   0.3352753 ]\n",
      " [-0.1499719  -0.64801556 -0.8851248 ]\n",
      " [-0.5106088  -0.1053677  -0.61352944]]\n",
      "47 0.7457528 [[-0.65857095 -1.9731116   0.34103325]\n",
      " [-0.15582128 -0.64796937 -0.87932163]\n",
      " [-0.502342   -0.10545512 -0.6217088 ]]\n",
      "48 0.74246097 [[-0.66410816 -1.9732928   0.34675166]\n",
      " [-0.16155604 -0.6478763  -0.87367994]\n",
      " [-0.494204   -0.10558254 -0.6297194 ]]\n",
      "49 0.7392652 [[-0.66961175 -1.973469    0.35243145]\n",
      " [-0.16718094 -0.6477362  -0.8681952 ]\n",
      " [-0.48619652 -0.1057436  -0.6375658 ]]\n",
      "50 0.7361616 [[-0.6750825  -1.9736404   0.3580736 ]\n",
      " [-0.17269422 -0.64755535 -0.8628627 ]\n",
      " [-0.47831488 -0.10593888 -0.64525217]]\n",
      "51 0.7331464 [[-0.6805221  -1.9738063   0.36367893]\n",
      " [-0.17809977 -0.6473342  -0.8576783 ]\n",
      " [-0.47055987 -0.1061632  -0.65278286]]\n",
      "52 0.73021597 [[-0.68593127 -1.9739665   0.3692484 ]\n",
      " [-0.18339673 -0.6470779  -0.85263765]\n",
      " [-0.4629277  -0.1064164  -0.6601618 ]]\n",
      "53 0.7273668 [[-0.69131154 -1.9741206   0.3747828 ]\n",
      " [-0.1885882  -0.6467874  -0.84773666]\n",
      " [-0.4554184  -0.10669443 -0.6673931 ]]\n",
      "54 0.7245957 [[-0.6966637  -1.9742687   0.38028297]\n",
      " [-0.19367406 -0.6464669  -0.8429713 ]\n",
      " [-0.44802883 -0.10699674 -0.6744804 ]]\n",
      "55 0.72189975 [[-0.7019889  -1.9744102   0.38574964]\n",
      " [-0.19865696 -0.64611745 -0.8383379 ]\n",
      " [-0.4407585  -0.10731986 -0.6814276 ]]\n",
      "56 0.7192757 [[-0.70728797 -1.9745451   0.3911836 ]\n",
      " [-0.20353697 -0.6457428  -0.83383256]\n",
      " [-0.43360448 -0.10766327 -0.6882382 ]]\n",
      "57 0.7167207 [[-0.712562   -1.974673    0.39658558]\n",
      " [-0.20831673 -0.64534384 -0.82945174]\n",
      " [-0.42656624 -0.10802391 -0.69491583]]\n",
      "58 0.7142322 [[-0.71781176 -1.974794    0.40195623]\n",
      " [-0.2129964  -0.64492404 -0.8251919 ]\n",
      " [-0.4196409  -0.10840129 -0.7014638 ]]\n",
      "59 0.71180737 [[-0.7230382  -1.9749076   0.40729624]\n",
      " [-0.21757855 -0.6444841  -0.8210497 ]\n",
      " [-0.41282788 -0.10879261 -0.70788556]]\n",
      "60 0.709444 [[-0.7282419  -1.975014    0.41260627]\n",
      " [-0.22206339 -0.6440272  -0.8170218 ]\n",
      " [-0.4061243  -0.10919758 -0.71418417]]\n",
      "61 0.7071395 [[-0.7334238  -1.9751127   0.4178869 ]\n",
      " [-0.22645348 -0.64355385 -0.813105  ]\n",
      " [-0.39952952 -0.10961364 -0.7203629 ]]\n",
      "62 0.7048915 [[-0.7385845  -1.9752039   0.4231388 ]\n",
      " [-0.23074919 -0.6430669  -0.80929625]\n",
      " [-0.39304087 -0.11004052 -0.7264247 ]]\n",
      "63 0.7026983 [[-0.7437248  -1.9752872   0.42836246]\n",
      " [-0.23495282 -0.6425669  -0.8055926 ]\n",
      " [-0.38665745 -0.11047601 -0.7323726 ]]\n",
      "64 0.70055723 [[-0.7488453  -1.9753628   0.4335585 ]\n",
      " [-0.239065   -0.6420563  -0.80199105]\n",
      " [-0.38037682 -0.11091983 -0.73820937]]\n",
      "65 0.69846654 [[-0.7539466  -1.9754304   0.4387274 ]\n",
      " [-0.24308786 -0.64153564 -0.79848886]\n",
      " [-0.37419793 -0.11137011 -0.74393797]]\n",
      "66 0.69642437 [[-0.75902927 -1.9754901   0.44386974]\n",
      " [-0.24702217 -0.64100695 -0.7950833 ]\n",
      " [-0.3681185  -0.11182654 -0.749561  ]]\n",
      "67 0.6944286 [[-0.76409394 -1.9755417   0.44898596]\n",
      " [-0.25087    -0.6404707  -0.7917717 ]\n",
      " [-0.36213744 -0.11228745 -0.7550812 ]]\n",
      "68 0.69247794 [[-0.769141   -1.9755852   0.4540766 ]\n",
      " [-0.25463203 -0.6399289  -0.7885515 ]\n",
      " [-0.35625234 -0.11275277 -0.76050097]]\n",
      "69 0.6905703 [[-0.7741711  -1.9756206   0.45914206]\n",
      " [-0.25831053 -0.63938165 -0.78542024]\n",
      " [-0.35046232 -0.1132208  -0.76582295]]\n",
      "70 0.68870425 [[-0.7791846  -1.9756479   0.46418282]\n",
      " [-0.26190603 -0.6388309  -0.7823755 ]\n",
      " [-0.34476486 -0.11369165 -0.7710495 ]]\n",
      "71 0.6868781 [[-0.784182   -1.975667    0.46919933]\n",
      " [-0.26542076 -0.6382767  -0.77941495]\n",
      " [-0.33915913 -0.11416376 -0.77618307]]\n",
      "72 0.6850904 [[-0.7891637  -1.975678    0.47419196]\n",
      " [-0.26885542 -0.6377207  -0.7765363 ]\n",
      " [-0.33364275 -0.1146373  -0.78122586]]\n",
      "73 0.68333995 [[-0.79413015 -1.9756807   0.47916117]\n",
      " [-0.27221206 -0.637163   -0.7737373 ]\n",
      " [-0.32821476 -0.11511095 -0.78618014]]\n",
      "74 0.681625 [[-0.7990817  -1.9756753   0.48410732]\n",
      " [-0.27549148 -0.6366049  -0.77101594]\n",
      " [-0.32287297 -0.11558476 -0.7910481 ]]\n",
      "75 0.67994463 [[-0.8040187  -1.9756618   0.48903075]\n",
      " [-0.27869564 -0.63604665 -0.76837003]\n",
      " [-0.31761625 -0.1160577  -0.79583186]]\n",
      "76 0.67829716 [[-0.8089414  -1.97564     0.49393186]\n",
      " [-0.28182545 -0.6354892  -0.7657976 ]\n",
      " [-0.3124426  -0.11652976 -0.8005335 ]]\n",
      "77 0.67668176 [[-0.81385034 -1.9756103   0.498811  ]\n",
      " [-0.2848826  -0.63493294 -0.7632967 ]\n",
      " [-0.30735072 -0.11700018 -0.8051549 ]]\n",
      "78 0.6750971 [[-0.8187457  -1.9755725   0.50366855]\n",
      " [-0.28786826 -0.6343785  -0.76086545]\n",
      " [-0.3023389  -0.11746879 -0.80969816]]\n",
      "79 0.6735419 [[-0.8236277  -1.9755267   0.50850475]\n",
      " [-0.29078394 -0.63382626 -0.758502  ]\n",
      " [-0.2974057  -0.11793508 -0.81416506]]\n",
      "80 0.67201555 [[-0.8284967  -1.9754729   0.51331997]\n",
      " [-0.2936309  -0.63327676 -0.75620455]\n",
      " [-0.2925495  -0.11839882 -0.8185575 ]]\n",
      "81 0.67051655 [[-0.8333529  -1.9754112   0.5181145 ]\n",
      " [-0.29641053 -0.63273036 -0.7539713 ]\n",
      " [-0.28776884 -0.11885967 -0.8228773 ]]\n",
      "82 0.66904414 [[-0.83819664 -1.9753417   0.52288866]\n",
      " [-0.2991241  -0.6321874  -0.7518006 ]\n",
      " [-0.28306222 -0.11931745 -0.82712615]]\n",
      "83 0.6675974 [[-0.84302807 -1.9752643   0.5276427 ]\n",
      " [-0.30177292 -0.6316483  -0.74969083]\n",
      " [-0.27842814 -0.1197719  -0.8313058 ]]\n",
      "84 0.6661754 [[-0.84784746 -1.9751792   0.532377  ]\n",
      " [-0.3043584  -0.6311133  -0.7476404 ]\n",
      " [-0.2738652  -0.12022278 -0.83541787]]\n",
      "85 0.6647773 [[-0.852655   -1.9750865   0.53709173]\n",
      " [-0.3068817  -0.63058263 -0.7456477 ]\n",
      " [-0.2693719  -0.12066995 -0.839464  ]]\n",
      "86 0.66340214 [[-0.85745084 -1.9749861   0.5417872 ]\n",
      " [-0.30934405 -0.6300567  -0.74371135]\n",
      " [-0.26494682 -0.12111332 -0.8434458 ]]\n",
      "87 0.6620492 [[-0.8622352  -1.9748782   0.54646367]\n",
      " [-0.31174695 -0.6295354  -0.74182975]\n",
      " [-0.2605887  -0.12155253 -0.84736466]]\n",
      "88 0.6607178 [[-0.8670082  -1.9747629   0.55112135]\n",
      " [-0.31409132 -0.6290192  -0.74000156]\n",
      " [-0.25629592 -0.12198778 -0.8512222 ]]\n",
      "89 0.6594072 [[-0.8717701  -1.9746403   0.5557605 ]\n",
      " [-0.31637865 -0.6285081  -0.73822534]\n",
      " [-0.25206733 -0.12241874 -0.85501987]]\n",
      "90 0.65811634 [[-0.876521   -1.9745102   0.56038135]\n",
      " [-0.31861    -0.62800235 -0.7364997 ]\n",
      " [-0.24790151 -0.12284543 -0.858759  ]]\n",
      "91 0.6568449 [[-0.881261   -1.974373    0.56498414]\n",
      " [-0.32078663 -0.627502   -0.7348234 ]\n",
      " [-0.24379714 -0.12326781 -0.862441  ]]\n",
      "92 0.6555923 [[-0.8859903  -1.9742286   0.5695691 ]\n",
      " [-0.32290974 -0.6270071  -0.7331952 ]\n",
      " [-0.239753   -0.12368571 -0.8660673 ]]\n",
      "93 0.6543578 [[-0.89070904 -1.9740772   0.57413644]\n",
      " [-0.32498032 -0.62651795 -0.73161376]\n",
      " [-0.23576762 -0.12409928 -0.8696391 ]]\n",
      "94 0.65314066 [[-0.89541733 -1.9739189   0.57868636]\n",
      " [-0.32699978 -0.6260343  -0.7300779 ]\n",
      " [-0.23184    -0.12450833 -0.8731577 ]]\n",
      "95 0.65194046 [[-0.90011525 -1.9737537   0.58321905]\n",
      " [-0.328969   -0.6255565  -0.7285865 ]\n",
      " [-0.2279687  -0.124913   -0.8766243 ]]\n",
      "96 0.6507567 [[-0.904803   -1.9735817   0.58773476]\n",
      " [-0.33088934 -0.6250843  -0.7271384 ]\n",
      " [-0.22415271 -0.12531306 -0.88004017]]\n",
      "97 0.6495887 [[-0.9094805  -1.973403    0.5922336 ]\n",
      " [-0.33276156 -0.62461805 -0.72573245]\n",
      " [-0.22039054 -0.12570892 -0.88340646]]\n",
      "98 0.64843595 [[-0.9141481  -1.9732176   0.5967158 ]\n",
      " [-0.3345872  -0.6241573  -0.72436756]\n",
      " [-0.21668144 -0.12610011 -0.88672435]]\n",
      "99 0.6472982 [[-0.91880566 -1.9730258   0.60118157]\n",
      " [-0.33636674 -0.6237026  -0.7230427 ]\n",
      " [-0.21302375 -0.12648717 -0.889995  ]]\n",
      "100 0.64617455 [[-0.92345345 -1.9728276   0.60563105]\n",
      " [-0.33810177 -0.6232534  -0.7217569 ]\n",
      " [-0.20941687 -0.12686965 -0.8932194 ]]\n",
      "101 0.64506507 [[-0.92809147 -1.972623    0.61006445]\n",
      " [-0.33979288 -0.6228101  -0.72050905]\n",
      " [-0.20585924 -0.127248   -0.89639866]]\n",
      "102 0.64396906 [[-0.9327198  -1.9724121   0.6144819 ]\n",
      " [-0.34144142 -0.6223724  -0.71929824]\n",
      " [-0.20235014 -0.12762195 -0.8995338 ]]\n",
      "103 0.6428861 [[-0.93733853 -1.9721951   0.61888367]\n",
      " [-0.34304807 -0.6219405  -0.7181235 ]\n",
      " [-0.19888818 -0.1279919  -0.90262586]]\n",
      "104 0.6418159 [[-0.94194776 -1.9719721   0.62326986]\n",
      " [-0.3446141  -0.6215141  -0.7169839 ]\n",
      " [-0.19547263 -0.12835753 -0.90567577]]\n",
      "105 0.6407578 [[-0.9465475  -1.9717431   0.62764055]\n",
      " [-0.34614018 -0.6210933  -0.7158786 ]\n",
      " [-0.1921022  -0.12871917 -0.90868455]]\n",
      "106 0.63971174 [[-0.95113784 -1.9715083   0.631996  ]\n",
      " [-0.34762743 -0.62067795 -0.7148067 ]\n",
      " [-0.18877605 -0.12907675 -0.9116531 ]]\n",
      "107 0.6386773 [[-0.9557188  -1.9712676   0.6363363 ]\n",
      " [-0.34907666 -0.6202681  -0.7137673 ]\n",
      " [-0.18549308 -0.12943046 -0.9145824 ]]\n",
      "108 0.6376542 [[-0.96029055 -1.9710212   0.64066166]\n",
      " [-0.3504889  -0.61986357 -0.7127596 ]\n",
      " [-0.18225248 -0.12978022 -0.9174732 ]]\n",
      "109 0.63664186 [[-0.96485305 -1.9707692   0.6449722 ]\n",
      " [-0.3518648  -0.61946446 -0.7117828 ]\n",
      " [-0.17905308 -0.13012633 -0.9203265 ]]\n",
      "110 0.63564026 [[-0.9694064  -1.9705116   0.64926803]\n",
      " [-0.35320553 -0.6190704  -0.7108362 ]\n",
      " [-0.17589423 -0.13046855 -0.9231431 ]]\n",
      "111 0.634649 [[-0.9739507  -1.9702486   0.6535493 ]\n",
      " [-0.3545116  -0.6186817  -0.7099188 ]\n",
      " [-0.17277473 -0.13080736 -0.92592376]]\n",
      "112 0.6336677 [[-0.9784859  -1.9699802   0.6578162 ]\n",
      " [-0.35578415 -0.61829793 -0.70903003]\n",
      " [-0.16969399 -0.13114245 -0.9286694 ]]\n",
      "113 0.63269615 [[-0.9830121  -1.9697067   0.6620688 ]\n",
      " [-0.35702375 -0.6179192  -0.7081691 ]\n",
      " [-0.16665089 -0.13147421 -0.93138075]]\n",
      "114 0.63173425 [[-0.98752934 -1.9694278   0.6663073 ]\n",
      " [-0.3582314  -0.6175453  -0.70733535]\n",
      " [-0.16364479 -0.13180248 -0.93405855]]\n",
      "115 0.6307815 [[-0.99203765 -1.969144    0.67053175]\n",
      " [-0.3594076  -0.61717635 -0.70652807]\n",
      " [-0.1606746  -0.13212761 -0.93670356]]\n",
      "116 0.6298376 [[-0.99653715 -1.968855    0.67474234]\n",
      " [-0.3605535  -0.61681193 -0.7057466 ]\n",
      " [-0.15773983 -0.13244939 -0.9393166 ]]\n",
      "117 0.6289027 [[-1.0010278  -1.9685612   0.67893916]\n",
      " [-0.36166945 -0.61645234 -0.70499027]\n",
      " [-0.15483934 -0.13276823 -0.9418982 ]]\n",
      "118 0.62797624 [[-1.0055097  -1.9682624   0.68312234]\n",
      " [-0.36275655 -0.6160971  -0.70425844]\n",
      " [-0.1519727  -0.13308385 -0.94444925]]\n",
      "119 0.627058 [[-1.0099828  -1.9679589   0.687292  ]\n",
      " [-0.36381513 -0.6157465  -0.70355046]\n",
      " [-0.14913876 -0.13339676 -0.9469703 ]]\n",
      "120 0.62614805 [[-1.0144472  -1.9676508   0.6914482 ]\n",
      " [-0.36484626 -0.6154001  -0.7028657 ]\n",
      " [-0.1463372  -0.1337066  -0.949462  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 0.62524587 [[-1.0189029  -1.967338    0.69559115]\n",
      " [-0.3658503  -0.61505806 -0.70220363]\n",
      " [-0.1435669  -0.13401385 -0.95192504]]\n",
      "122 0.62435156 [[-1.02335    -1.9670206   0.6997209 ]\n",
      " [-0.36682823 -0.6147201  -0.70156366]\n",
      " [-0.1408275  -0.13431823 -0.95436007]]\n",
      "123 0.6234646 [[-1.0277885  -1.9666989   0.70383763]\n",
      " [-0.3677804  -0.6143864  -0.70094526]\n",
      " [-0.13811797 -0.13462017 -0.9567677 ]]\n",
      "124 0.62258506 [[-1.0322185  -1.9663727   0.7079414 ]\n",
      " [-0.36870775 -0.61405647 -0.7003478 ]\n",
      " [-0.13543795 -0.13491943 -0.95914847]]\n",
      "125 0.6217128 [[-1.0366399  -1.9660423   0.7120324 ]\n",
      " [-0.36961058 -0.61373067 -0.69977075]\n",
      " [-0.13278645 -0.13521644 -0.96150297]]\n",
      "126 0.6208475 [[-1.0410529  -1.9657075   0.7161106 ]\n",
      " [-0.37048984 -0.61340845 -0.6992137 ]\n",
      " [-0.13016316 -0.13551085 -0.96383184]]\n",
      "127 0.61998904 [[-1.0454574  -1.9653686   0.72017616]\n",
      " [-0.37134573 -0.6130902  -0.698676  ]\n",
      " [-0.12756705 -0.13580325 -0.96613556]]\n",
      "128 0.61913717 [[-1.0498534  -1.9650255   0.7242292 ]\n",
      " [-0.37217933 -0.6127754  -0.69815725]\n",
      " [-0.124998   -0.13609317 -0.96841466]]\n",
      "129 0.6182921 [[-1.0542411  -1.9646785   0.7282698 ]\n",
      " [-0.37299067 -0.61246437 -0.6976569 ]\n",
      " [-0.12245485 -0.13638125 -0.97066975]]\n",
      "130 0.61745334 [[-1.0586205  -1.9643275   0.73229814]\n",
      " [-0.37378085 -0.6121565  -0.6971746 ]\n",
      " [-0.11993755 -0.13666698 -0.9729013 ]]\n",
      "131 0.61662066 [[-1.0629914  -1.9639726   0.7363142 ]\n",
      " [-0.37454987 -0.61185235 -0.69670975]\n",
      " [-0.117445   -0.13695101 -0.9751098 ]]\n",
      "132 0.6157943 [[-1.0673541  -1.9636137   0.7403181 ]\n",
      " [-0.3752988  -0.6115512  -0.69626194]\n",
      " [-0.11497716 -0.13723288 -0.9772958 ]]\n",
      "133 0.61497396 [[-1.0717084  -1.9632512   0.74431   ]\n",
      " [-0.3760276  -0.61125356 -0.69583076]\n",
      " [-0.11253295 -0.13751318 -0.97945976]]\n",
      "134 0.6141594 [[-1.0760547  -1.962885    0.74829   ]\n",
      " [-0.3767373  -0.6109588  -0.6954158 ]\n",
      " [-0.1101123  -0.13779145 -0.98160213]]\n",
      "135 0.61335075 [[-1.0803927  -1.9625151   0.7522581 ]\n",
      " [-0.377428   -0.6106673  -0.69501656]\n",
      " [-0.10771433 -0.1380682  -0.98372334]]\n",
      "136 0.6125476 [[-1.0847225  -1.9621416   0.7562145 ]\n",
      " [-0.37810048 -0.6103786  -0.6946327 ]\n",
      " [-0.10533883 -0.13834317 -0.98582387]]\n",
      "137 0.61175 [[-1.0890442  -1.9617647   0.7601592 ]\n",
      " [-0.3787549  -0.61009306 -0.6942639 ]\n",
      " [-0.10298494 -0.13861671 -0.9879042 ]]\n",
      "138 0.6109579 [[-1.0933578  -1.9613843   0.7640923 ]\n",
      " [-0.37939212 -0.6098101  -0.6939096 ]\n",
      " [-0.10065259 -0.13888858 -0.98996466]]\n",
      "139 0.610171 [[-1.0976633  -1.9610004   0.76801395]\n",
      " [-0.38001215 -0.6095301  -0.69356954]\n",
      " [-0.09834093 -0.13915916 -0.99200577]]\n",
      "140 0.6093894 [[-1.1019607  -1.9606133   0.7719242 ]\n",
      " [-0.3806158  -0.60925263 -0.6932433 ]\n",
      " [-0.09604979 -0.1394282  -0.99402785]]\n",
      "141 0.6086131 [[-1.10625    -1.9602228   0.7758231 ]\n",
      " [-0.38120317 -0.608978   -0.6929306 ]\n",
      " [-0.09377845 -0.13969609 -0.99603134]]\n",
      "142 0.6078416 [[-1.1105314  -1.9598291   0.77971077]\n",
      " [-0.38177502 -0.60870564 -0.692631  ]\n",
      " [-0.09152675 -0.1399625  -0.99801666]]\n",
      "143 0.6070751 [[-1.1148049  -1.9594322   0.7835873 ]\n",
      " [-0.3823314  -0.60843605 -0.6923442 ]\n",
      " [-0.08929393 -0.14022788 -0.9999841 ]]\n",
      "144 0.6063136 [[-1.1190703  -1.9590322   0.78745276]\n",
      " [-0.38287306 -0.6081687  -0.6920699 ]\n",
      " [-0.08707992 -0.14049192 -1.001934  ]]\n",
      "145 0.6055566 [[-1.1233279  -1.9586291   0.7913072 ]\n",
      " [-0.38340008 -0.60790384 -0.69180775]\n",
      " [-0.084884   -0.14075495 -1.0038669 ]]\n",
      "146 0.6048044 [[-1.1275775  -1.958223    0.79515076]\n",
      " [-0.38391304 -0.6076412  -0.6915574 ]\n",
      " [-0.08270597 -0.14101686 -1.0057831 ]]\n",
      "147 0.60405684 [[-1.1318194  -1.9578139   0.7989835 ]\n",
      " [-0.38441223 -0.6073808  -0.69131863]\n",
      " [-0.08054534 -0.14127775 -1.0076828 ]]\n",
      "148 0.6033137 [[-1.1360533  -1.9574019   0.8028055 ]\n",
      " [-0.38489795 -0.60712266 -0.69109106]\n",
      " [-0.07840171 -0.14153771 -1.0095664 ]]\n",
      "149 0.6025751 [[-1.1402795  -1.956987    0.8066168 ]\n",
      " [-0.3853707  -0.60686654 -0.6908744 ]\n",
      " [-0.07627483 -0.14179668 -1.0114343 ]]\n",
      "150 0.60184085 [[-1.1444979  -1.9565693   0.81041753]\n",
      " [-0.38583064 -0.6066126  -0.6906684 ]\n",
      " [-0.07416416 -0.14205486 -1.0132868 ]]\n",
      "151 0.60111094 [[-1.1487086  -1.9561489   0.81420773]\n",
      " [-0.3862783  -0.60636055 -0.6904728 ]\n",
      " [-0.07206955 -0.14231203 -1.0151242 ]]\n",
      "152 0.6003851 [[-1.1529115  -1.9557257   0.8179875 ]\n",
      " [-0.3867138  -0.60611063 -0.69028723]\n",
      " [-0.06999045 -0.14256856 -1.0169468 ]]\n",
      "153 0.59966373 [[-1.1571068  -1.9552997   0.8217569 ]\n",
      " [-0.38713765 -0.6058625  -0.6901115 ]\n",
      " [-0.06792669 -0.1428242  -1.0187548 ]]\n",
      "154 0.59894615 [[-1.1612943  -1.9548712   0.825516  ]\n",
      " [-0.38754997 -0.60561633 -0.68994534]\n",
      " [-0.06587778 -0.14307922 -1.0205487 ]]\n",
      "155 0.59823287 [[-1.1654743  -1.95444     0.8292649 ]\n",
      " [-0.38795125 -0.6053719  -0.6897885 ]\n",
      " [-0.06384358 -0.14333345 -1.0223286 ]]\n",
      "156 0.59752345 [[-1.1696466  -1.9540063   0.8330036 ]\n",
      " [-0.3883416  -0.6051293  -0.68964076]\n",
      " [-0.06182359 -0.1435871  -1.0240949 ]]\n",
      "157 0.59681785 [[-1.1738114  -1.9535701   0.8367322 ]\n",
      " [-0.3887215  -0.6048883  -0.6895018 ]\n",
      " [-0.05981766 -0.14384006 -1.0258479 ]]\n",
      "158 0.5961163 [[-1.1779687  -1.9531314   0.8404508 ]\n",
      " [-0.38909099 -0.6046492  -0.68937147]\n",
      " [-0.05782532 -0.14409256 -1.0275878 ]]\n",
      "159 0.59541845 [[-1.1821185  -1.9526904   0.8441595 ]\n",
      " [-0.38945064 -0.60441154 -0.68924946]\n",
      " [-0.05584654 -0.14434436 -1.0293148 ]]\n",
      "160 0.5947243 [[-1.1862608  -1.9522469   0.8478583 ]\n",
      " [-0.38980037 -0.6041757  -0.6891356 ]\n",
      " [-0.05388069 -0.14459579 -1.0310291 ]]\n",
      "161 0.594034 [[-1.1903956  -1.9518011   0.8515473 ]\n",
      " [-0.3901408  -0.60394114 -0.6890297 ]\n",
      " [-0.05192786 -0.1448465  -1.0327312 ]]\n",
      "162 0.5933472 [[-1.194523   -1.951353    0.8552265 ]\n",
      " [-0.39047182 -0.6037083  -0.68893147]\n",
      " [-0.04998741 -0.14509697 -1.0344212 ]]\n",
      "163 0.59266406 [[-1.198643   -1.9509025   0.8588961 ]\n",
      " [-0.390794   -0.6034768  -0.68884075]\n",
      " [-0.04805946 -0.1453468  -1.0360993 ]]\n",
      "164 0.5919844 [[-1.2027556  -1.9504498   0.86255604]\n",
      " [-0.39110723 -0.603247   -0.68875736]\n",
      " [-0.04614333 -0.14559646 -1.0377659 ]]\n",
      "165 0.59130824 [[-1.2068609  -1.9499949   0.86620647]\n",
      " [-0.39141223 -0.60301834 -0.68868107]\n",
      " [-0.04423926 -0.14584546 -1.039421  ]]\n",
      "166 0.5906357 [[-1.2109588  -1.9495379   0.8698474 ]\n",
      " [-0.39170867 -0.6027913  -0.6886116 ]\n",
      " [-0.0423465  -0.14609434 -1.0410649 ]]\n",
      "167 0.58996654 [[-1.2150495  -1.9490787   0.87347895]\n",
      " [-0.39199725 -0.6025654  -0.688549  ]\n",
      " [-0.04046524 -0.14634266 -1.0426978 ]]\n",
      "168 0.5893005 [[-1.2191329  -1.9486175   0.8771011 ]\n",
      " [-0.39227778 -0.602341   -0.68849283]\n",
      " [-0.03859489 -0.14659086 -1.04432   ]]\n",
      "169 0.58863807 [[-1.2232091  -1.9481541   0.880714  ]\n",
      " [-0.39255083 -0.6021177  -0.68844306]\n",
      " [-0.03673552 -0.14683859 -1.0459316 ]]\n",
      "170 0.58797884 [[-1.2272781  -1.9476887   0.88431764]\n",
      " [-0.3928163  -0.6018958  -0.6883995 ]\n",
      " [-0.03488666 -0.14708614 -1.0475329 ]]\n",
      "171 0.5873228 [[-1.2313399  -1.9472213   0.8879121 ]\n",
      " [-0.39307463 -0.60167503 -0.68836194]\n",
      " [-0.03304831 -0.14733334 -1.0491241 ]]\n",
      "172 0.5866699 [[-1.2353946  -1.946752    0.89149743]\n",
      " [-0.3933258  -0.60145557 -0.68833023]\n",
      " [-0.03122007 -0.1475804  -1.0507053 ]]\n",
      "173 0.58602023 [[-1.2394422  -1.9462807   0.8950738 ]\n",
      " [-0.3935702  -0.6012372  -0.6883042 ]\n",
      " [-0.02940192 -0.14782713 -1.0522767 ]]\n",
      "174 0.5853737 [[-1.2434827  -1.9458076   0.8986411 ]\n",
      " [-0.39380783 -0.60102004 -0.6882837 ]\n",
      " [-0.02759344 -0.14807375 -1.0538386 ]]\n",
      "175 0.58473015 [[-1.2475162  -1.9453325   0.9021995 ]\n",
      " [-0.39403912 -0.60080385 -0.68826854]\n",
      " [-0.02579471 -0.14832002 -1.0553911 ]]\n",
      "176 0.58408976 [[-1.2515426  -1.9448557   0.905749  ]\n",
      " [-0.39426392 -0.600589   -0.68825865]\n",
      " [-0.02400521 -0.14856628 -1.0569344 ]]\n",
      "177 0.5834523 [[-1.255562   -1.944377    0.9092897 ]\n",
      " [-0.39448273 -0.600375   -0.6882538 ]\n",
      " [-0.02222509 -0.1488122  -1.0584686 ]]\n",
      "178 0.5828178 [[-1.2595744  -1.9438965   0.91282165]\n",
      " [-0.39469534 -0.60016227 -0.68825394]\n",
      " [-0.02045382 -0.1490582  -1.0599939 ]]\n",
      "179 0.5821862 [[-1.26358    -1.9434142   0.9163449 ]\n",
      " [-0.39490235 -0.5999503  -0.6882589 ]\n",
      " [-0.01869163 -0.14930381 -1.0615104 ]]\n",
      "180 0.58155775 [[-1.2675785  -1.9429302   0.91985947]\n",
      " [-0.3951035  -0.59973955 -0.6882685 ]\n",
      " [-0.01693792 -0.14954947 -1.0630184 ]]\n",
      "181 0.580932 [[-1.2715702  -1.9424446   0.9233655 ]\n",
      " [-0.39529926 -0.5995297  -0.6882826 ]\n",
      " [-0.01519284 -0.14979489 -1.0645181 ]]\n",
      "182 0.58030915 [[-1.275555   -1.9419572   0.92686296]\n",
      " [-0.39548957 -0.5993209  -0.6883011 ]\n",
      " [-0.01345604 -0.1500403  -1.0660095 ]]\n",
      "183 0.57968885 [[-1.279533   -1.9414682   0.930352  ]\n",
      " [-0.3956747  -0.599113   -0.68832386]\n",
      " [-0.01172747 -0.15028557 -1.0674928 ]]\n",
      "184 0.57907176 [[-1.2835042  -1.9409776   0.9338325 ]\n",
      " [-0.39585477 -0.598906   -0.6883508 ]\n",
      " [-0.01000697 -0.1505307  -1.0689682 ]]\n",
      "185 0.57845724 [[-1.2874687  -1.9404854   0.93730474]\n",
      " [-0.39602977 -0.59870005 -0.6883818 ]\n",
      " [-0.0082942  -0.1507759  -1.0704358 ]]\n",
      "186 0.57784534 [[-1.2914264  -1.9399915   0.9407686 ]\n",
      " [-0.39620012 -0.5984948  -0.68841666]\n",
      " [-0.00658934 -0.15102085 -1.0718957 ]]\n",
      "187 0.5772361 [[-1.2953774  -1.939496    0.9442242 ]\n",
      " [-0.39636567 -0.5982906  -0.6884553 ]\n",
      " [-0.00489192 -0.1512659  -1.073348  ]]\n",
      "188 0.57662964 [[-1.2993217  -1.9389992   0.94767153]\n",
      " [-0.3965267  -0.5980872  -0.68849766]\n",
      " [-0.00320199 -0.15151082 -1.0747931 ]]\n",
      "189 0.57602584 [[-1.3032593e+00 -1.9385008e+00  9.5111078e-01]\n",
      " [-3.9668331e-01 -5.9788465e-01 -6.8854356e-01]\n",
      " [-1.5193356e-03 -1.5175574e-01 -1.0762309e+00]]\n",
      "190 0.5754245 [[-1.3071903e+00 -1.9380008e+00  9.5454186e-01]\n",
      " [-3.9683563e-01 -5.9768295e-01 -6.8859291e-01]\n",
      " [ 1.5613611e-04 -1.5200061e-01 -1.0776615e+00]]\n",
      "191 0.5748259 [[-1.3111147e+00 -1.9374994e+00  9.5796490e-01]\n",
      " [-3.9698368e-01 -5.9748214e-01 -6.8864566e-01]\n",
      " [ 1.8246222e-03 -1.5224548e-01 -1.0790851e+00]]\n",
      "192 0.5742298 [[-1.3150325  -1.9369966   0.96137995]\n",
      " [-0.39712778 -0.59728205 -0.6887017 ]\n",
      " [ 0.00348611 -0.15249023 -1.0805018 ]]\n",
      "193 0.57363623 [[-1.3189437  -1.9364923   0.964787  ]\n",
      " [-0.39726782 -0.5970828  -0.6887609 ]\n",
      " [ 0.0051409  -0.152735   -1.0819118 ]]\n",
      "194 0.57304513 [[-1.3228486  -1.9359868   0.96818614]\n",
      " [-0.39740407 -0.5968843  -0.6888231 ]\n",
      " [ 0.00678898 -0.15297973 -1.0833151 ]]\n",
      "195 0.57245654 [[-1.3267468  -1.9354798   0.9715774 ]\n",
      " [-0.39753646 -0.59668666 -0.6888884 ]\n",
      " [ 0.00843065 -0.15322454 -1.084712  ]]\n",
      "196 0.5718704 [[-1.3306386  -1.9349715   0.97496086]\n",
      " [-0.39766532 -0.5964897  -0.68895644]\n",
      " [ 0.01006577 -0.15346926 -1.0861024 ]]\n",
      "197 0.5712867 [[-1.334524   -1.9344618   0.9783366 ]\n",
      " [-0.39779058 -0.59629357 -0.68902737]\n",
      " [ 0.01169464 -0.153714   -1.0874865 ]]\n",
      "198 0.5707053 [[-1.338403   -1.9339509   0.98170453]\n",
      " [-0.39791244 -0.5960981  -0.689101  ]\n",
      " [ 0.01331729 -0.15395872 -1.0888644 ]]\n",
      "199 0.5701265 [[-1.3422756  -1.9334387   0.98506486]\n",
      " [-0.3980309  -0.59590346 -0.6891772 ]\n",
      " [ 0.01493391 -0.15420349 -1.0902363 ]]\n",
      "200 0.56954986 [[-1.3461418  -1.9329251   0.98841757]\n",
      " [-0.3981461  -0.5957095  -0.689256  ]\n",
      " [ 0.01654455 -0.15444826 -1.0916022 ]]\n",
      "Prediction :  [2 2 2]\n",
      "Accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([3]), name='bias')\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X:x_data, Y:y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "    \n",
    "    # predict\n",
    "    print(\"Prediction : \", sess.run(prediction, feed_dict={X:x_test}))\n",
    "    # accuracy\n",
    "    print(\"Accuracy : \", sess.run(accuracy, feed_dict={X:x_test, Y:y_test}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.632794 [[ 0.4928637  -1.4864905  -0.94068223]\n",
      " [ 2.441493   -4.0612245   0.55021375]\n",
      " [ 1.4081042  -2.9355216  -0.17546272]]\n",
      "1 23.226044 [[-0.6313178  -0.9239905  -0.37900072]\n",
      " [-1.6818442  -1.4362245   2.048551  ]\n",
      " [-2.7160442  -0.1230216   1.1361855 ]]\n",
      "2 21.950668 [[-0.25631788 -0.3615104  -1.3164806 ]\n",
      " [ 0.7556555   1.1887355  -3.0139084 ]\n",
      " [-0.2785442   2.6894577  -4.1137934 ]]\n",
      "3 17.134869 [[ 0.11840475 -1.298733   -0.75398064]\n",
      " [ 3.192592   -2.748201   -1.5139085 ]\n",
      " [ 2.1586692  -1.0602558  -2.8012934 ]]\n",
      "4 25.060349 [[-1.0065949  -0.7362331  -0.19148093]\n",
      " [-0.93240714 -0.12320113 -0.0139091 ]\n",
      " [-1.9663303   1.7522438  -1.4887937 ]]\n",
      "5 10.614988 [[-0.6316203  -1.6520079   0.34931922]\n",
      " [ 1.5050418  -4.016238    1.4416795 ]\n",
      " [ 0.47114396 -1.9750154  -0.19900858]]\n",
      "6 14.632747 [[-0.62606263 -1.0895079  -0.21873844]\n",
      " [ 1.887414   -1.3912382  -1.5656924 ]\n",
      " [ 0.81988376  0.8374846  -3.360248  ]]\n",
      "7 10.725235 [[-1.7467132  -0.531255    0.34365916]\n",
      " [-2.2287312   1.2251115  -0.06589735]\n",
      " [-3.2919822   3.6369534  -2.0478506 ]]\n",
      "8 23.877731 [[-1.3717132  -1.4685175   0.9059217 ]\n",
      " [ 0.20876884 -2.711913    1.4336275 ]\n",
      " [-0.8544822  -0.11280918 -0.7355883 ]]\n",
      "9 11.824869 [[-0.9967331  -0.9060292  -0.03154665]\n",
      " [ 2.6462238  -0.08693671 -3.6288033 ]\n",
      " [ 1.5829654   2.699636   -5.9854803 ]]\n",
      "10 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "11 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "12 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "13 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "14 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "15 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "16 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "17 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "18 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "19 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "20 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "21 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "22 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "23 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "24 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "25 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "26 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "27 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "28 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "29 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "30 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "31 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "32 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "33 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "34 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "35 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "36 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "37 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "38 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "39 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "40 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "41 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "42 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "43 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "44 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "45 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "46 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "47 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "48 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "49 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "50 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "51 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "52 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "53 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "54 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "55 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "56 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "57 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "58 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "59 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "60 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "61 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "62 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "63 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "64 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "65 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "66 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "67 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "68 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "69 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "70 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "71 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "72 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "73 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "74 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "75 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "76 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "77 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "78 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "79 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "80 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "81 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "82 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "83 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "84 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "85 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "86 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "87 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "88 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "89 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "90 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "91 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "92 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "93 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "94 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "95 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "96 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "97 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "98 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "99 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "100 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "101 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "102 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "103 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "104 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "105 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "106 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "107 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "108 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "109 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "110 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "111 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "112 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "113 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "114 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "115 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "116 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "117 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "118 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "119 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "120 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "121 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "122 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "123 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "124 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "125 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "126 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "127 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "128 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "129 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "130 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "131 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "132 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "133 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "134 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "135 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "136 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "137 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "138 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "139 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "140 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "141 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "142 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "143 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "144 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "145 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "146 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "147 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "148 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "149 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "150 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "151 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "152 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "153 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "154 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "155 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "156 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "157 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "158 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "159 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "160 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "161 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "162 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "163 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "164 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "165 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "166 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "167 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "168 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "169 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "170 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "171 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "172 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "173 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "174 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "175 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "176 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "177 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "178 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "179 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "180 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "181 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "182 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "183 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "184 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "185 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "186 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "187 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "188 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "189 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "190 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "191 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "192 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "193 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "194 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "195 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "196 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "197 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "198 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "199 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "200 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  [0 0 0]\n",
      "Accuracy :  0.0\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([3]), name='bias')\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.5).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X:x_data, Y:y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "    \n",
    "    # predict\n",
    "    print(\"Prediction : \", sess.run(prediction, feed_dict={X:x_test}))\n",
    "    # accuracy\n",
    "    print(\"Accuracy : \", sess.run(accuracy, feed_dict={X:x_test, Y:y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "1 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "2 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "3 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "4 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "5 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "6 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "7 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "8 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "9 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "10 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "11 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "12 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "13 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "14 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "15 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "16 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "17 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "18 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "19 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "20 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "21 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "22 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "23 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "24 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "25 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "26 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "27 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "28 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "29 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "30 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "31 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "32 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "33 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "34 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "35 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "36 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "37 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "38 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "39 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "40 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "41 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "42 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "43 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "44 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "45 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "46 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "47 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "48 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "49 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "50 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "51 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "52 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "53 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "54 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "55 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "56 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "57 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "58 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "59 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "60 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "61 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "62 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "63 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "64 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "65 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "66 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "67 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "68 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "69 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "70 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "71 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "72 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "73 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "74 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "75 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "76 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "77 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "78 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "79 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "80 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "81 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "82 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "83 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "84 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "85 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "86 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "87 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "88 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "89 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "90 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "91 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "92 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "93 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "94 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "95 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "96 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "97 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "98 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "99 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "100 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "101 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "102 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "103 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "104 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "105 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "106 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "107 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "108 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "109 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "110 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "111 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "112 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "113 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "114 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "115 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "116 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "117 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "119 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "120 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "121 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "122 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "123 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "124 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "125 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "126 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "127 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "128 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "129 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "130 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "131 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "132 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "133 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "134 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "135 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "136 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "137 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "138 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "139 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "140 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "141 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "142 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "143 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "144 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "145 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "146 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "147 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "148 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "149 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "150 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "151 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "152 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "153 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "154 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "155 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "156 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "157 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "158 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "159 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "160 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "161 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "162 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "163 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "164 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "165 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "166 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "167 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "168 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "169 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "170 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "171 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "172 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "173 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "174 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "175 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "176 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "177 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "178 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "179 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "180 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "181 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "182 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "183 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "184 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "185 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "186 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "187 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "188 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "189 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "190 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "191 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "192 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "193 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "194 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "195 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "196 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "197 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "198 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "199 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "200 2.9345984 [[ 0.53219664 -0.04326498 -0.3540067 ]\n",
      " [ 0.38889655  1.7420006   0.10040051]\n",
      " [ 1.6471255  -0.85674876  0.5065184 ]]\n",
      "Prediction :  [1 0 0]\n",
      "Accuracy :  0.0\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([3]), name='bias')\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-10).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X:x_data, Y:y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "    \n",
    "    # predict\n",
    "    print(\"Prediction : \", sess.run(prediction, feed_dict={X:x_test}))\n",
    "    # accuracy\n",
    "    print(\"Accuracy : \", sess.run(accuracy, feed_dict={X:x_test, Y:y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([4,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X:x_data, Y:y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized data ( min-max scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Library 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.         1.         1.        ]\n",
      " [0.70548491 0.70439552 1.         0.71881783 0.83755792]\n",
      " [0.54412549 0.50274824 0.57608696 0.60646801 0.6606331 ]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
      " [0.51436    0.4258239  0.30434783 0.58504805 0.42624401]\n",
      " [0.49556179 0.4258239  0.31521739 0.48131134 0.49276137]\n",
      " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
      " [0.         0.07747099 0.5326087  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "xy = scaler.fit_transform(xy)\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler 함수 정의하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999999  0.9999999  0.         0.9999999  0.9999999 ]\n",
      " [0.70548484 0.70439545 0.9999999  0.71881775 0.83755783]\n",
      " [0.54412544 0.50274819 0.5760869  0.60646794 0.66063303]\n",
      " [0.33890349 0.3136802  0.10869564 0.4598913  0.43800914]\n",
      " [0.51435995 0.42582385 0.3043478  0.585048   0.42624397]\n",
      " [0.49556174 0.42582385 0.31521736 0.48131129 0.49276132]\n",
      " [0.11436063 0.         0.20652172 0.22007774 0.18597236]\n",
      " [0.         0.07747099 0.53260864 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "xy = MinMaxScaler(xy)\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 Cost:  0.109844536 \n",
      "Prediction: \n",
      " [[ 1.080426  ]\n",
      " [ 1.059934  ]\n",
      " [ 0.5458162 ]\n",
      " [-0.03296906]\n",
      " [ 0.3302685 ]\n",
      " [ 0.29675347]\n",
      " [-0.439185  ]\n",
      " [-0.38649875]]\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([4,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X:x_data, Y:y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
