{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep NN : 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-a94cbd4c83ea>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 0001 cost = 0.296503939\n",
      "Epoch: 0002 cost = 0.103318040\n",
      "Epoch: 0003 cost = 0.070010280\n",
      "Epoch: 0004 cost = 0.053372705\n",
      "Epoch: 0005 cost = 0.041612854\n",
      "Epoch: 0006 cost = 0.035084590\n",
      "Epoch: 0007 cost = 0.028809172\n",
      "Epoch: 0008 cost = 0.026726423\n",
      "Epoch: 0009 cost = 0.022903945\n",
      "Epoch: 0010 cost = 0.019833833\n",
      "Epoch: 0011 cost = 0.019378301\n",
      "Epoch: 0012 cost = 0.014779972\n",
      "Epoch: 0013 cost = 0.017211413\n",
      "Epoch: 0014 cost = 0.017244510\n",
      "Epoch: 0015 cost = 0.015399025\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9823\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x140d5bef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
