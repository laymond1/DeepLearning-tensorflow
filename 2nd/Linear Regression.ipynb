{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X and Y train data\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "# Variable은 tensorflow의 variable이다. 즉, Trainable Variable이다.\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight') # tensorflow variable 의 shape\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bais')\n",
    "\n",
    "# Hypothesis Wx + b\n",
    "hypothesis = W * x_train + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train)) # reduce_mean : 평균"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2 & 3. Run/Update graph and get result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.820347 [-0.4813711] [0.25029433]\n",
      "200 0.031284098 [0.7945729] [0.46698406]\n",
      "400 0.011945804 [0.8730585] [0.28856778]\n",
      "600 0.004561489 [0.9215579] [0.17831743]\n",
      "800 0.0017418014 [0.95152754] [0.11018934]\n",
      "1000 0.0006651035 [0.97004706] [0.06809026]\n",
      "1200 0.0002539709 [0.98149085] [0.04207571]\n",
      "1400 9.697896e-05 [0.98856246] [0.02600029]\n",
      "1600 3.7031718e-05 [0.99293226] [0.01606663]\n",
      "1800 1.41402115e-05 [0.99563265] [0.0099281]\n",
      "2000 5.399251e-06 [0.9973012] [0.00613494]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# W와 b 변수를 사용하기 전에 항상 initialize 해줘야 한다\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 200 == 0: # 예제에서는 20으로.\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 초기값 W와 b는 랜덤하지만 점점 1과 0에 가까워진다. tf.Variable이라는 것이 이렇게 변수의 값이 조정되어 변한다는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder를 이용한 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 105.43837 [-0.9400371] [-0.42701972]\n",
      "200 0.039947823 [1.1293224] [0.6331051]\n",
      "400 0.010307776 [1.0656916] [0.8628325]\n",
      "600 0.0026597264 [1.0333691] [0.9795266]\n",
      "800 0.0006862961 [1.0169506] [1.038803]\n",
      "1000 0.00017708151 [1.0086102] [1.0689142]\n",
      "1200 4.5693414e-05 [1.0043738] [1.0842092]\n",
      "1400 1.1791315e-05 [1.0022218] [1.0919784]\n",
      "1600 3.0425374e-06 [1.0011288] [1.0959251]\n",
      "1800 7.8558e-07 [1.0005735] [1.0979296]\n",
      "2000 2.0295207e-07 [1.0002916] [1.0989475]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "hypothesis = W*X + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], feed_dict={X:[1,2,3,4,5], Y:[2.1,3.1,4.1,5.1,6.1]})\n",
    "    if step % 200 == 0:  # 20으로.\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1004057]\n",
      "[3.5996766]\n",
      "[2.5993848 4.599968 ]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict={X:[5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X:[2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X:[1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
